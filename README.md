# Udacity-Data-Analyst-Nanodegree

## Project Overview

### P0: Explore Weather Trends

The first chapter was an introduction to the following projects of the Data Analyst Nanodegree.

First chapter project was about weather trends - it required to apply (atleast) the following steps:

- Extract data from a database using a SQL query
- Calculate a moving average
- Create a line chart

### P1: Investigate a Dataset (Investigate a Dataset No-show appointments)

This chapter was all about the data analysis process as whole. From gathering to cleaning, assessing and wrangling to exploring and visualizing the data over the programming workflow and communication was everything included.

This project included therefore all steps of the typical data analysis process. This includes:

- posing questionss
- gather, wrangle and clean data
- communicate answers to the questions
- assited through visualizations and statistics.

Out of the project:

> This dataset collects information From 100k medical appointments in Brazil and is focused on the question of whether or not patients show up for their appointment.
> What factors are important for us to know in order to predict if a patient will show up for their scheduled appointment?

### P2: Analyze A/B Test Results

Following chapter was filled with _a lot_ of information. Data Types, Notation, Mean, Standard Deviation, Correlation, Data Shapes, Outliers, Bias, Dangers, Probability and Bayes, Distributions, Central Limit Theorem, Bootstrapping, Confidence Intervals, Hypothesis Testing, A/B Tests, Linear Regression, Logistic Regression and more..

The goal of this project is working to understand the results of an A/B test run by an e-commerce website. The company has developed a new web page in order to try and increase the number of users who "convert," meaning the number of users who decide to pay for the company's product.
In the end we brought everything we've learned together to analyze this A/B test properly.

### P3: Gather, Clean and Analyze Twitter Data (WeRateDogsâ„¢ (@dog_rates))

This chapter was a deep dive into the data wrangling part of the data analysis process. I learned about the difference between messy and dirty data, how tidy data should look like, about the assessing, defining, cleaning and testing process, etc. Moreover, also working on different file types and different methods of gathering data.

In this project I had to deal with the reality of dirty and messy data. Gathering data from different sources (for example the Twitter API), identified issues with the dataset in terms of tidiness and quality. Afterwards we had to solve these problems while documenting each step. The end of the project was then focused on the exploration of the data.

### P4: Communicate Data Findings

The final chapter was focused on proper visualization of data. We learned about chart junk, uni-, bi- and multivariate visualization, use of color, data/ink ratio, the lief factor, other encodings, [...].

The task of the final project was to analyze and visualize real-world data. I chose the Ford GoBike dataset.
